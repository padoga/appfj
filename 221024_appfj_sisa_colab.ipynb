{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/padoga/appfj/blob/main/221024_appfj_sisa_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사용법**\n",
        "1. 좌상단 메뉴에서 '파일' > '드라이브에 사본 저장'\n",
        "\n",
        "  실수로 원본을 변형할 가능성이 있으니 사본 저장 후 그 사본을 사용해주세요\n",
        "2. Ctrl+F9 눌러 모든 셀 실행하기\n",
        "3. 좌측 탭에서 워드 파일 다운로드 받기 \n",
        "\n",
        "  구글 colab에서 pdf 변환은 안 된다고 하네요.. 워드 파일 실행시켜 직접 pdf 변환 해주시길\n",
        "\n",
        "끝!  "
      ],
      "metadata": {
        "id": "zHw2DUuuqxzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmTPQNg2k-5-",
        "outputId": "836c959e-e5be-4232-a3e5-072f70d43214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.9.24)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,035 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Fetched 6,763 kB in 3s (2,337 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (105.0.5195.102-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ2xwUqFkUfh"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import time\n",
        "from datetime import date, timedelta\n",
        "from selenium.webdriver.common.by import By"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')        # Head-less 설정\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver', options=options)"
      ],
      "metadata": {
        "id": "pyQ4Ww65lHJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delta_day = timedelta(days=1)\n",
        "delta_week = timedelta(weeks=1)\n",
        "\n",
        "def get_dow(date_here):\n",
        "    dow_list = ['mon','tue','wed','thu','fri','sat','sun']\n",
        "    dow_index = date_here.weekday()\n",
        "    return dow_list[dow_index]\n",
        "\n",
        "def get_start_date():\n",
        "    start_date = date.today() # 오늘 날짜 확인\n",
        "    start_day = get_dow(start_date) # 오늘 요일을 시작 요일로  \n",
        "    while start_day != 'sun': # 시작 요일이 일요일이 될 때까지\n",
        "        start_date = start_date - delta_day # 날짜에서 하루를 뺌 \n",
        "        start_day = get_dow(start_date) # 뺀 날짜의 요일을 시작 요일로 \n",
        "    stop_date = start_date - delta_week\n",
        "    return start_date, stop_date\n",
        "\n",
        "def get_week(date_here):\n",
        "    first_day = date_here.replace(day=1)\n",
        "    week, weekday = divmod(date_here.day+ first_day.weekday() - 1, 7) #(몫, 나머지)\n",
        "    return week+1\n",
        "    "
      ],
      "metadata": {
        "id": "78a6GIMokaOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://kims4all.kr/login.aspx?ReturnUrl=%2fAPPFJ%2fDefault.aspx'\n",
        "\n",
        "start_date, stop_date = get_start_date() # 시작 날짜, 끝 날짜 구해서 저장 \n",
        "print(start_date, stop_date)\n",
        "\n",
        "scrap_count = 0\n",
        "error_count = 0\n",
        "\n",
        "title_list=[]\n",
        "definition_list=[]\n",
        "example_list=[]  \n",
        "note_list=[]\n",
        "\n",
        "driver.get(url)\n",
        "\n",
        "time.sleep(1)\n",
        "\n",
        "\n",
        "# 로그인\n",
        "driver.find_element(By.NAME, \"Login1$UserName\").send_keys('박윤주')\n",
        "driver.find_element(By.NAME, \"Login1$Password\").send_keys('1234')\n",
        "driver.find_element(By.NAME, 'Login1$LoginButton').click()\n",
        "time.sleep(1)\n",
        "\n",
        "# 상식 list 페이지 접근\n",
        "driver.get('http://kims4all.kr/APPFJ/MediaTest/List.aspx?BoardName=generalKnowledge')\n",
        "\n",
        "# 첫 아이템 접근\n",
        "submit_element = driver.find_element(By.XPATH, '//*[@id=\"ctl00_ContentPlaceHolder1_GridView1_ctl02_Label1\"]')\n",
        "submit_element.click()\n",
        "time.sleep(1)\n",
        "\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "item_num = int(soup.select_one('#ctl00_ContentPlaceHolder1_lblNum').get_text()) # 최초 페이지 넘버 저장 \n",
        "datestamp = date.fromisoformat(soup.select_one('#ctl00_ContentPlaceHolder1_lblPostDate').get_text()[0:10]) # 최초 페이지 날짜 저장 \n",
        "\n",
        "# 시작 아이템 페이지로 이동 \n",
        "while datestamp > start_date:\n",
        "    item_num -= 1\n",
        "    driver.get(f'http://kims4all.kr/APPFJ/MediaTest/View.aspx?Num={item_num}&BoardName=generalKnowledge')\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "    datestamp_new = date.fromisoformat(soup.select_one('#ctl00_ContentPlaceHolder1_lblPostDate').get_text()[0:10])\n",
        "    if datestamp_new != date(1,1,1):\n",
        "        datestamp = datestamp_new\n",
        "\n",
        "\n",
        "# 스크래핑 \n",
        "while datestamp > stop_date : \n",
        "\n",
        "    scrap_count += 1\n",
        "    \n",
        "    driver.get(f'http://kims4all.kr/APPFJ/MediaTest/View.aspx?Num={item_num}&BoardName=generalKnowledge')\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "    datestamp_new = date.fromisoformat(soup.select_one('#ctl00_ContentPlaceHolder1_lblPostDate').get_text()[0:10])\n",
        "    if datestamp_new != date(1,1,1):\n",
        "        datestamp = datestamp_new\n",
        "    \n",
        "    # 표제어 가져오기\n",
        "    title = soup.select_one('#ctl00_ContentPlaceHolder1_lblWordNPhrase').get_text()\n",
        "    \n",
        "    if title == '':\n",
        "        \n",
        "        error_count +=1\n",
        "        print(f'{error_count}번째 삭제된 페이지 발견: {item_num}')\n",
        "        item_num -=1\n",
        "        \n",
        "        continue\n",
        "\n",
        "    title_list.append(title) \n",
        "\n",
        "    # 정의 가져오기 \n",
        "\n",
        "    definition_pre = soup.find('span', {'id':\"ctl00_ContentPlaceHolder1_lblSentence\"}).find_all(text=True)\n",
        "    time.sleep(.5)\n",
        "    definition = '\\n'.join(definition_pre)\n",
        "    definition_list.append(definition) \n",
        "\n",
        "    # 예문 가져오기 \n",
        "    example_pre = soup.find('span', {'id':\"ctl00_ContentPlaceHolder1_lblNote\"}).find_all(text=True)\n",
        "    example = '\\n'.join(example_pre)\n",
        "    example_list.append(example)\n",
        "\n",
        "    # 특기사항 가져오기 \n",
        "    note_pre = soup.find('span', {'id':\"ctl00_ContentPlaceHolder1_lblQuestions\"}).find_all(text=True)\n",
        "    time.sleep(.5)\n",
        "    note = '\\n'.join(note_pre)\n",
        "    note_list.append(note) \n",
        "    \n",
        "    item_num -=1\n",
        "        \n",
        "    if scrap_count%5 == 0 :\n",
        "            print(f'상식 정리 진행 중... 정리된 상식 {scrap_count}개')\n",
        "    \n",
        "print(f'상식 정리 완료. 정리된 상식 총 {len(title_list)}개, 삭제된 페이지 {error_count}개')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ8HUvqYkaav",
        "outputId": "eed36114-898f-4675-fde2-480612ad0afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-23 2022-10-16\n",
            "1번째 삭제된 페이지 발견: 6400\n",
            "상식 정리 진행 중... 정리된 상식 5개\n",
            "2번째 삭제된 페이지 발견: 6396\n",
            "3번째 삭제된 페이지 발견: 6395\n",
            "4번째 삭제된 페이지 발견: 6392\n",
            "상식 정리 진행 중... 정리된 상식 15개\n",
            "상식 정리 완료. 정리된 상식 총 11개, 삭제된 페이지 4개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCqnraK9nYrP",
        "outputId": "8d30fb5e-c58a-44fd-c65b-34edffa81705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.7/dist-packages (0.8.11)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.9.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document \n",
        "from docx.shared import Pt\n",
        "# from docx2pdf import convert\n",
        "\n",
        "# install 방법: prompt에서 pip install python-docx\n",
        "# pip install docx2pdf"
      ],
      "metadata": {
        "id": "srmOyXCOklqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 월, 주 구하기 \n",
        "if start_date.month != stop_date.month:\n",
        "    start_first_day = start_date.replace(day=1)\n",
        "    if start_first_day.weekday() > 1: \n",
        "        month = start_date.month\n",
        "        week = get_week(start_date)\n",
        "    else: \n",
        "      month = stop_date.month\n",
        "      week = get_week(stop_date)\n",
        "else:\n",
        "  month = start_date.month\n",
        "  week = get_week(start_date)"
      ],
      "metadata": {
        "id": "5ib3w89gknrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = Document()\n",
        "doc_num=0\n",
        "\n",
        "style = document.styles['Normal']\n",
        "style.font.name = '맑은 고딕'\n",
        "style.font.size = Pt(10)\n",
        "\n",
        "for i in range(len(title_list)):\n",
        "\n",
        "    \n",
        "    paragraph=document.add_paragraph(f'{doc_num+1}. '+title_list[doc_num])\n",
        "    document.add_paragraph(definition_list[doc_num])\n",
        "    \n",
        "    if example_list[doc_num] != '':\n",
        "        document.add_paragraph(example_list[doc_num])\n",
        "    \n",
        "    if note_list[doc_num] !='':\n",
        "        document.add_paragraph(note_list[doc_num])\n",
        "    document.add_paragraph()\n",
        "    \n",
        "    doc_num +=1\n",
        "\n",
        "document.save(f'아프지 {month}월 {week}주차 시사상식.docx')\n",
        "\n",
        "# pdf 파일 생성 \n",
        "# 경로지정\n",
        "# input_file = 'C:\\\\Users\\\\judya\\\\Desktop\\\\취준\\\\상식\\\\아프지\\\\' + f'아프지 {month}월 {week}주차 시사상식.docx'\n",
        "# output_file = 'C:\\\\Users\\\\judya\\\\Desktop\\\\취준\\\\상식\\\\아프지\\\\' + f'아프지 {month}월 {week}주차 시사상식.pdf'    \n",
        "\n",
        "# convert(input_file, output_file)\n",
        "\n",
        "print(f'{month}월 {week}주차 상식 파일 생성 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOsGuIG3kqrD",
        "outputId": "bb7ddf6f-8662-437c-d065-9d4752a3202d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10월 4주차 상식 파일 생성 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<- 왼쪽 폴더 아이콘을 눌러 파일을 확인하세요!\n",
        "\n",
        "파일명 오른쪽에 나오는 쩜 세개 누르면 다운로드 가능합니다."
      ],
      "metadata": {
        "id": "7AvYbq1nqL0m"
      }
    }
  ]
}